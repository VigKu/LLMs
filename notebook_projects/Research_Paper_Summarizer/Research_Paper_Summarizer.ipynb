{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd6801f-c1f3-4256-9467-bc2e8ad88036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "import pdfplumber\n",
    "from ipywidgets import widgets\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f13eb2-a0a6-42d9-86a1-3412fae0090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to do this one time on your computer\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a671d0ca-da69-45c8-9c77-24f46d6a6fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"llama3.2\"\n",
    "openai = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3842a0-18f8-4b38-af7a-f5b86e184833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt():\n",
    "    system_prompt = \"\"\"You are an expert research summarizer. That summarizes the content of the research paper in no more than 700 words. The research summary that you provide should include the following:\n",
    "    1) Objective/Problem - State the research goal or hypothesis.\n",
    "    2) Background - Briefly explain the context and significance.\n",
    "    3) Methods - Summarize the approach or methodology.\n",
    "    4) Key Findings - Highlight the main results or insights.\n",
    "    5) Conclusion - Provide the implications or contributions of the study.\n",
    "    6) Future Directions - Suggest areas for further research or exploration.\n",
    "    7) Limitations - Highlight constraints or challenges in the study.\n",
    "    8) Potential Applications - Discuss how the findings can be applied in real-world scenarios.\n",
    "    Keep all points concise, clear, and focused and generate output in markdown.\"\"\"\n",
    "    return system_prompt\n",
    "\n",
    "\n",
    "def messages_for(user_prompt, system_prompt):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    \n",
    "def summarize(user_prompt, system_prompt):\n",
    "    # Generate messages using the user_prompt\n",
    "    messages = messages_for(user_prompt, system_prompt)\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=MODEL,  # Correct model name\n",
    "            messages=messages,\n",
    "            max_tokens = 700 # Pass the generated messages\n",
    "        )\n",
    "        # Return the content from the API response correctly\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        # Instead of printing, return an error message that can be displayed\n",
    "        return f\"Error in OpenAI API call: {e}\"\n",
    "        \n",
    "def extract_text_and_generate_summary(change):\n",
    "    print(\"Extracting text from pdf.\")\n",
    "    if upload_widget.value:\n",
    "        # Extract the first uploaded file\n",
    "        uploaded_file = list(upload_widget.value)[0]\n",
    "        pdf_file = uploaded_file['content']\n",
    "\n",
    "        # Extract text from the PDF\n",
    "        try:\n",
    "            with pdfplumber.open(BytesIO(pdf_file)) as pdf:\n",
    "                extracted_text = \"\\n\".join(page.extract_text() for page in pdf.pages)\n",
    "\n",
    "            # Generate the user prompt\n",
    "            user_prompt = (\n",
    "                f\"You are looking at the text from a research paper. Summarize it in no more than 700 words. \"\n",
    "                f\"The output should be in markdown.\\n\\n{extracted_text}\"\n",
    "            )\n",
    "\n",
    "            # Generate the system prompt\n",
    "            system_prompt = get_system_prompt()\n",
    "\n",
    "            # Get the summarized response\n",
    "            response = summarize(user_prompt, system_prompt)\n",
    "            \n",
    "            if response:\n",
    "                # Use IPython's display method to show markdown below the cell\n",
    "                display(Markdown(response))\n",
    "        \n",
    "        except Exception as e:\n",
    "            # If there's an error, display it using Markdown\n",
    "            display(Markdown(f\"**Error:** {str(e)}\"))\n",
    "\n",
    "    # Reset the upload widget\n",
    "    upload_widget.value = ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f93222-507f-4f3b-9a43-6d3b5fd41744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42427a69-fbe3-4ba0-94c6-3975e7827d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a9025-9886-4f09-8d4a-39062e5381ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_widget = widgets.FileUpload(\n",
    "    accept='.pdf', \n",
    "    multiple=False,\n",
    "    description='Upload PDF',\n",
    "    layout=widgets.Layout(width='300px',height = '100px', border='2px dashed #cccccc', padding='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8015ffa-e0e9-4b58-bcaa-ede8c272ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_widget.observe(extract_text_and_generate_summary, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62213f6-4560-450a-9bc5-09429652ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response seen in logs\n",
    "display(upload_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9460aebf-6170-4974-996b-e173996de084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda1589-c2e9-450d-88e4-24b761f1d7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
